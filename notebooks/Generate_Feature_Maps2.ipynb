{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, color\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import pdb\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
    "           'wide_resnet50_2', 'wide_resnet101_2']\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "}\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, tanh=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.tanh = tanh\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        if self.tanh:\n",
    "            out = nn.Tanh()(out)\n",
    "        else:\n",
    "            out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, tanh=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1], tanh=tanh)\n",
    "        # self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "        #                                dilate=replace_stride_with_dilation[2])\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False, tanh=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks-1):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "        layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                            base_width=self.base_width, dilation=self.dilation,\n",
    "                            norm_layer=norm_layer, tanh=tanh))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "#         featmap = x\n",
    "#         x = self.layer4(x)\n",
    "#         x = self.avgpool(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, tanh=False):\n",
    "        super(Discriminator, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 256\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_cls = nn.Linear(512 * block.expansion, 10)\n",
    "        self.fc_adv = nn.Linear(512 * block.expansion, 1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False, tanh=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks-1):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "        layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                            base_width=self.base_width, dilation=self.dilation,\n",
    "                            norm_layer=norm_layer, tanh=tanh))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.layer4(x)\n",
    "        feats = self.avgpool(x)\n",
    "        feats = torch.flatten(feats, 1)\n",
    "        logits_cls = self.fc_cls(feats)\n",
    "        logits_adv = self.fc_adv(feats)\n",
    "        return feats, logits_cls, logits_adv\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, progress, layer_4, fixed, tanh=False):\n",
    "    model = ResNet(block, layers, tanh=tanh)\n",
    "    if pretrained:\n",
    "        model_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "#         model_dict = model_zoo.load_url(\"https://download.pytorch.org/models/resnet18-5c106cde.pth\")\n",
    "        def remove_layer4(model_dict):\n",
    "            layer4_params = []\n",
    "            for k, v in model_dict.items():\n",
    "                if k.startswith('layer4'):\n",
    "                    layer4_params.append(k)\n",
    "            for p in layer4_params:\n",
    "                model_dict.pop(p, None)\n",
    "            return model_dict\n",
    "\n",
    "        model_dict = remove_layer4(model_dict)\n",
    "        model_dict.pop('fc.weight', None)\n",
    "        model_dict.pop('fc.bias', None)\n",
    "        model.load_state_dict(model_dict)\n",
    "        # TODO: layer4 param not used\n",
    "        # if layer_4:\n",
    "        #     for name,child in model.named_children():\n",
    "        #         if name != 'layer4':\n",
    "        #             for param in child.parameters():\n",
    "        #                 param.requires_grad = False\n",
    "        if fixed:\n",
    "            for name,child in model.named_children():\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "#         model.eval()\n",
    "#         model.load_state_dict(state_dict)\n",
    "    return model\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, width = 12, deconv = False):\n",
    "        super(Generator, self).__init__()\n",
    "        # Input size: [batch, 3, 32, 32]\n",
    "        # Output size: [batch, 3, 32, 32]\n",
    "        nfms = width\n",
    "        if deconv:\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.ConvTranspose2d(512, nfms*8, 4, stride=2, padding=1),  # [batch, width*8, 2, 2]\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.ConvTranspose2d(nfms*8, 256, 4, stride=2, padding=1),  # [batch, width*4, 4, 4]\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.ConvTranspose2d(256, 256, 4, stride=2, padding=1),  # [batch, width*2, 8, 8]\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.ConvTranspose2d(256, 256, 4, stride=2, padding=1),  # [batch, width*1, 16, 16]\n",
    "                nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=0),# [batch, width*1, 14, 14]\n",
    "            )\n",
    "        else:\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Upsample(size=(2,2), mode='nearest'),\n",
    "                nn.Conv2d(512, nfms*8, kernel_size=2, stride=1, padding=1), \n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                # state size. \n",
    "                nn.Upsample(size=(4,4), mode='nearest'),\n",
    "                nn.Conv2d(nfms*8, 256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                # state size. (ngf*8) x 4 x 4\n",
    "                nn.Upsample(size=(8,8), mode='nearest'),\n",
    "                nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                # state size. (ngf*4) x 8 x 8\n",
    "                nn.Upsample(size=(14,14), mode='nearest'),\n",
    "                nn.Conv2d( 256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            )\n",
    "        self.output_act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        decoded = self.decoder(x)\n",
    "        decoded = self.output_act(decoded)\n",
    "        return decoded\n",
    "    \n",
    "def resnet18(pretrained=False, progress=True, layer_4=False, fixed=False, tanh=False):\n",
    "    r\"\"\"ResNet-18 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        print(\"Loaded pretrained resnet model\")\n",
    "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress, layer_4, fixed, tanh=tanh)\n",
    "\n",
    "def discriminator():\n",
    "    return Discriminator(BasicBlock, [2,2,2,2], tanh=False)\n",
    "\n",
    "def generator():\n",
    "    return Generator(width=32, deconv=True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10(Dataset):\n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "    meta = {\n",
    "        'filename': 'batches.meta',\n",
    "        'key': 'label_names',\n",
    "        'md5': '5ff9c542aee3614f3951f8cda6e48888',\n",
    "    }\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "\n",
    "        super(CIFAR10, self).__init__()\n",
    "        self.root = root\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if self.train:\n",
    "            downloaded_list = self.train_list\n",
    "        else:\n",
    "            downloaded_list = self.test_list\n",
    "\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        self.transform = transform\n",
    "        self.target_transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), ])\n",
    "        \n",
    "        # now load the picked numpy arrays\n",
    "        for file_name, checksum in downloaded_list:\n",
    "            file_path = os.path.join(self.root, self.base_folder, file_name)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                entry = pickle.load(f, encoding='latin1')\n",
    "                self.data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.targets.extend(entry['labels'])\n",
    "                else:\n",
    "                    self.targets.extend(entry['fine_labels'])\n",
    "\n",
    "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "        self._load_meta()\n",
    "\n",
    "    def _load_meta(self):\n",
    "        path = os.path.join(self.root, self.base_folder, self.meta['filename'])\n",
    "     \n",
    "        with open(path, 'rb') as infile:\n",
    "            data = pickle.load(infile, encoding='latin1')\n",
    "            self.classes = data[self.meta['key']]\n",
    "        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n",
    "    \n",
    "    def _ret_data(self):\n",
    "        return self.data, self.targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img_, target = self.data[index], self.targets[index]\n",
    "        img_224 = Image.fromarray(img_)\n",
    "        img_32 = Image.fromarray(img_)\n",
    "        img_224 = img_224.resize((224,224), resample=0)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_224 = self.transform(img_224)\n",
    "            img_32 = self.target_transform(img_32)\n",
    "#             target = self.target_transform(target)\n",
    "            \n",
    "        return img_224, img_32, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CIFAR100(CIFAR10):\n",
    "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "\n",
    "    This is a subclass of the `CIFAR10` Dataset.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-100-python'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n",
    "    meta = {\n",
    "        'filename': 'meta',\n",
    "        'key': 'fine_label_names',\n",
    "        'md5': '7973b15100ade9c7d40fb424638fde48',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "trainset = CIFAR10(root='../data', train=True,\n",
    "                   download=True, transform=transform)\n",
    "testset = CIFAR10(root='../data', train=False,\n",
    "                  download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
    "                                          shuffle=False, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([100, 3, 224, 224]) torch.Size([100, 3, 32, 32])\ntensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n        6, 0, 0, 7])\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.919844pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.919844\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.919844 \r\nL 251.565 248.919844 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 225.041719 \r\nL 244.365 225.041719 \r\nL 244.365 7.601719 \r\nL 26.925 7.601719 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p8f7d223966)\">\r\n    <image height=\"218\" id=\"image3b3030410f\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAABHNCSVQICAgIfAhkiAAAEdVJREFUeJztnUuPHOd5hd+6dvVtpudCDmc45IgULUshoViGZMWx40WQCFk4QOwgPyEbI8gP8cJA/oSBBHDW2ciLOAYS5GIjER3ZkWRGFE1yZnqmp2f6Wl1VWSQr4zvH8GD8kkDOs6wXX926ThdwvrfOF/3Zn/9pY4Dnv/gYlWw1nwa3V0u4O1uVNa5VuNZYBGtxnAa3RxbjMRHbX4JrKd5nmuHrbqfhffb7XThmp7cOa71WG9a6Oa7lrSy4fRne/H+DOrA0q8hvHeF7VYBzbGU5HNNq4/PIWgU+VqcHa22yzw64/71eH47JM3we+G4IIa4MCU0IByQ0IRyQ0IRwQEITwgEJTQgH0qrEFu3o5ALWpufj4PZyVsIxzN4nJStrYv0Dizkm+4vIdEFErP+G1CzFHnmahsettbGdfbq+CWs769dhbWMTX3hvLTwV0uvgKY2uYcs6jfA1j62CtcUq/IxEMZmSWS5hLSH3viHPDvut8zy8zyzDx4piMm0EK0KIK0NCE8IBCU0IByQ0IRyQ0IRwQEITwoE0S1qwWC2xXXl6NAlun08WeH/Eaq1ItzdpEjcDXf8RHXQ5mgbfjzoJW+dmZmmzCm7fKnD3fmuI7fFP8mN8rJ0BrO3cvBbcfufaNt5fFD53M7Okj63/nPyHL+rwb1OV+FhGvo6wBtdKMi1QrfA9LsG5VBUek8TY+tcbTQgHJDQhHJDQhHBAQhPCAQlNCAfSjLhl3TbORzgfzYPbK9Id3Bh2h5qIuYTk/wAMI0bUrygSSE+xGXbMusBt/WqOc0He7WzB2ofjZ7D28L8ew9qz58Pg9uXBHThm9xV8rwakc7vVxVkdBXBvG/LsLOfEzcZGoBU4FsSyLJx7Y2aWg4FFQTJZlBkixItFQhPCAQlNCAckNCEckNCEcEBCE8KBdDYPNwebmS2IpVouQTMv88CJrZ6ymG7yf1A1YW+3IlMJlyUm51+TWg9kYbxO4ra/EOFm7zeKHVh7m2R1/LgO/54fPT6CY56ejmBt/GwD1jb29mBt61r4/FtdfD+WKzx9siIN5CnNE8HjkiSco9LQZwBPT+iNJoQDEpoQDkhoQjggoQnhgIQmhAMSmhAOpOPTE1g8en74a++QmeoJcf5bEY6lziP8hQFaYHROToTZsAw+dYFLWSfc8d3dDmd4mJnVMe4Srxr8VcV1Eqv9u6Db/m4T/hLDzOyjBe5w/+yzcCy8mdnRCR43vxWeUtq5cwDHFIM1WDOWN0NyQWgNfBJQkWmGmnxGoDeaEA5IaEI4IKEJ4YCEJoQDEpoQDkhoQjiQPiZhLuMhtm8bZCOTLvyCRCZvkk529m8wqcOrR5ZgVUkzs5pFT9MAIbIaKOkEv/fmO8Htt977JhwTE5s+qkhMN7GsB8CaLpbY3t+o8BccB2Pc2f/k6DmsHU/Cz9XhTx/BMe3reAXUzd1dWEtTvKrqxQVe0bZon4fPA6wEamYWNTjiXW80IRyQ0IRwQEITwgEJTQgHJDQhHJDQhHAgffYUd+9HRIdpK2xzNjHuwr/zyquwtk1Wv5zMcCf4yTRs0VZnZ3DMeBy2bs3M6pp0dJNgllaBO+q/+JX3gtuPbuPM+3/99L9hbXiGz3+xwCtcGpiCSMlv1o7xlxPbWzdh7eD2a7C2DwKEnh0/hWMOSW30DE8zrNXk2khtmoenIHodHJrU9PAXBnqjCeGAhCaEAxKaEA5IaEI4IKEJ4YCEJoQD6dbePizOxuGlWM3MbB7u+F67jnPh9z6HLd9mgjvIy2N8GrOLsPVfVbjTPiJhPxQSwNNpb8PaD/75YXD7X7//j3DMEemMX4J1D/4X/N+ZgHChVoY73LsF7lYf9HCA0LXBANZu7N0Ibr938zYc8/ldPBVyAb4GMDM7OcPrClQlniZJ0vAzcpLh+1u0LvcFihDiipDQhHBAQhPCAQlNCAckNCEciO69+S700p5++jEcWIFVFm8c3IVj0gg7WOPjU1wb41VJyyrcRFuvcNZFU18uEtxI5knevo6Pl4WbTVfE/YxT/B/YybHb121j56tCWSkk78RaJLskJ/kwOb62dhFuzN3s4cby/W28uuj+LnZ8OwUs2WKOXce8CDcc9wb43m9dwxHveqMJ4YCEJoQDEpoQDkhoQjggoQnhgIQmhANRf/cN6O1OSWNrnoVt5HYHZ2eYYcs3aXCtIf8HcRa2YVNmPbew51sA69nMLC+wdZ52tvA+8/Xw/sh0AXH3LSpYwzS26kuQJ7KYkYbuEmeQ1BGZJiHnkaLubJJdYiCjxsxsvctq+Lna6GOrftANPyOdHj5Wi8wl6I0mhAMSmhAOSGhCOCChCeGAhCaEAxKaEA6kX/3aH8BikmBrNLKwNZokxLLOsHWepKTN2vA+kwTZ+yTbocDHyjLSod/C5x+TjvqkAftcYes8jvCKpWWCY8tLshroahne5xLkv5iZlVP8FcR0PoO1Jfl6IirBtZFVTivyNUBi+JrLGp/HxQxPT7TB85Oh39LM8oQ8H7AihLgyJDQhHJDQhHBAQhPCAQlNCAckNCEcSN/6wtuw+PqDN2FtOAwHmyyBhWxmtiShOJXhzu2m/vVjriOS311V+DwaMo64z8bywstV+HjHQxxItFph6zwmTfODNRzFvQRN/xdTvKKqgekTM7P2gKxwWeLzX4GvBaolnu7IE/zFQod8VVHkPVhrpfjaUDjSijyL5NHXG00IDyQ0IRyQ0IRwQEITwgEJTQgHJDQhHEi/993vwuK3/nIT1n77rfvB7as5C3MhgTlr2IaNgYVvZmYV6GQnFjhdDZQsBlob7gQ/H+NVJ5Ms/LXALw5xt/digb3ieo671bsdnF+Puu2jjHTap7hbfXMbBxItF3ifZ2dnwe3DY7y0a4N+ZzOzGD9ziwY/CGmKv7jIi/B9ZOFNbE0HvdGEcEBCE8IBCU0IByQ0IRyQ0IRwIMqyG7Ab9p0vvwsHfuevvh3cvruLV7787MkTWItj3JTbJ1kja2CVyCTHuSApyfdoyHnUht2to9MhrK1thN25mvzPTUhWx8UEn8fJKXY/+4Nww3EJVm81M4safI4ZifCuiQM3BxklF5MLOKapses4neJxp6MTfB4z3ExdTkHjM3E/O11lhgjxQpHQhHBAQhPCAQlNCAckNCEckNCEcCAtSBPqo58/grXvv//94PY/+vofwjE//Ke/h7VjYv3vkHM8uLUf3N7ewg3Re/sHsNZfxzkYBVnRcb2Pm6JR3sWKWMWf/PQDWHv0Kb5Xy5KstAli1xMyfdImeRwlC8kgZHm4UTlJSDYMqfX7eJXZvZ3XyD5xc/nFJGz9n5+HG6LNzOZzPF2gN5oQDkhoQjggoQnhgIQmhAMSmhAOSGhCOJDefO23YHFzYwPWfvSTj4PbFyBK2cwsa+WwdjgKR4ybmUVzbCNf370ZHkO6zp+f4Q73p2f4PBqyzzjCtfX19eD27S2cuXHjWvi6zHhmyNkIX9sYXNv54REc83gygbWTMba6V2hVT8OrquYtnE8SE3t/fS18f83MBuCLBTOzHpkWaHXC0xoHr9yCY6oKX7PeaEI4IKEJ4YCEJoQDEpoQDkhoQjggoQnhQPR73/gL2O5dZNiOXy7CNnKWY+2++zvvwNpgDQfm9MjfwYP74WjyrX1sj89LHG7z8OHPYO0ffvgveJ8zHKaTZ+Gc8c/dvQPH3H/j87C2t40t67UOvo81sJ/HI2zTH57iVUmfHuNpgckFnhYYjUbB7csS38Msx1nteQt/VVGtyEqsJZ4m6QzC1v+DB+HnzcxsfR1PF+iNJoQDEpoQDkhoQjggoQnhgIQmhAMSmhAOpG+/9QAWa9KBHYMc+l6Ow1z6Ka4d3AyH7JiZXdvCwTclyGRfzsLZ6WZmnS62g8s5tph/9G//DmuzhoTigIj6H3/wH3DM372Pz/HebRwu9OUvfRHWvvaVLwW337qHO9L3a1xbLrE9vqpwbXQatvdL0v3eJsFIUYTXADg/D69yamZ2fIxz+dvd8DTJzg28tkSno+x9IV4oEpoQDkhoQjggoQnhgIQmhAPpn/zxe7DIXMduO+ywMNexXWBXZrbEWReTCV5N89EnnwS3nw9xw+vtO9i1G/RwbsWDN7ADV8Z4XAGyUjrkfnTbJH58DceWLxv8mw0n4cyQuI0bdssVXrkzJit+Jgm+ts56uCk6jfF5zIiLPBrhxue9m7uwtn1tG9biJOwid9u4aZvEmuiNJoQHEpoQDkhoQjggoQnhgIQmhAMSmhAORD/44BHshl1McUMmsjkjw821bZL7sNbBten4GNbqVdjOzsDqlmZmKbHOG9QBbGYzkjXS1Pj84zj8f5aleEogJeeRgQwSM7MIHMvMrAGx5QvSHPzxk8ewNicrfubEqq/AuCLB1vloiHNNPnvyCNbuP8Arft59FU/z9DpgVdIIrxIa40dfbzQhPJDQhHBAQhPCAQlNCAckNCEckNCEcCD9m7/9Hiyy3I0sDdu3rIP51VdwLsjX3/t9WFtbx93qcR32VFs5icaOsUVbkfPvRvjLhCYcXWJmZjGwhJkVX9e4az4iFrORGtpjTcYU5KuE4Rh3zT8e4i8uZrPwtFG1wNMMyxmeWlksprD20c/xPT64g2Pjkyj8xUVEsmEiI9Y/rAghrgwJTQgHJDQhHJDQhHBAQhPCAQlNCAdSFrXMwmNQ53mvj/e3d2sP1pIMa76I8T6Rvd802Gpl9nhK7XFs7Q5PcBhQrxeONM9zvKJqnuDu9/mCfEVguOs/BceLiS199+AurO3dvA1rI2L9j87CnfjnZ+GocDOzknxJYhH+Xba28OqoLRCaZGbwjjALn0y66I0mhAcSmhAOSGhCOCChCeGAhCaEAxKaEA5EHx6eQW80I93lKcpdj3Abe0xqKVi508wsa0j+Ozz7y/2HkFkBGLJjZvaT/3wIazs74VUi+/0+HFNV+JqPTi5gzRLcbd/phY83meKvNCKSoR8l+Ga12vg8IvD1RItM8STk+WC+OvlQw4xM16CzZ09VBKaaftU4IcQVIaEJ4YCEJoQDEpoQDkhoQjggoQnhQLoa4xCVotOFNdS9X9U4YIW445aQVB+WRYO8XdZlTffGwldItnqaYxu8icBUCMmnZ8vFjmYLWJtXuNacTYLbmb0/J8daznFHfRLj6YkbO1vB7fdfvwfHZBHeX0N+MzZfQzOOcOlS6I0mhAMSmhAOSGhCOCChCeGAhCaEA+mgjd0yq/CKjjEImGaNlQlZxZJFiTNQjkdEIrUZKL7bjLtbN3ZxvDQch9xIM2sVOH58ejSGtcNTXKuBl1au8HVNz89hrVnh7JJ+B+dx9FrhZy4l9zdusJvNXUfyYDHbEXUjk0MpElyIF4yEJoQDEpoQDkhoQjggoQnhgIQmhANpt4NXxqxWJKfhimEWLXFUYbEmOSN0xUx6LHwmbRLvjVbvjMmVFRluON7dwiugdgt8HrNF+PecTHHj8CwhcdsbOPNkZ2sTj+uHI9ITkpPCrHjaQH7Jn5o1kCNYZLzeaEI4IKEJ4YCEJoQDEpoQDkhoQjggoQnhQFqTbvua5Wdc1iK/DJewWunuyHVdruffqPUPY6nJFwY5+dJh/zq2ziuSkTG+CNv4I5AlYmb24c/wSqbddjj7w8ysReLCU1BiTxR5TC8POyD7IuAS6I0mhAMSmhAOSGhCOCChCeGAhCaEAxKaEA6kzKZ3tfBfEmjQiyv4PKoShyY1xN5vgxU100G4m97MbGcbTyWsdXFk/GKOY8Zr8MVIQyZXfiO/C9vnFT/7eqMJ4YCEJoQDEpoQDkhoQjggoQnhgIQmhAPRcDiEHmdV+YXz/H+ETp/QlUfJ78J2CbL+G/J/uyjxsdIsvOqrmZnVeFxymeQbZy4ztcWmIPRGE8IBCU0IByQ0IRyQ0IRwQEITwgE1Ff8SL801s9+FBGgwPw/tkjXztkg0OV39kizhGsHjsbPH+/tNNBxf9XOgN5oQDkhoQjggoQnhgIQmhAMSmhAOSGhCOJCyxuHVagVrL40NfsW8NNfFHGtSo8OADd6wlSoveR4s7jyKwrWGdERH5GAvi72vpmIhXjASmhAOSGhCOCChCeGAhCaEAxKaEA78D2MfnGWJ6Po0AAAAAElFTkSuQmCC\" y=\"-7.041719\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m32b42f23f4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.3225\" xlink:href=\"#m32b42f23f4\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.14125 239.640156)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.2975\" xlink:href=\"#m32b42f23f4\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(61.11625 239.640156)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"98.2725\" xlink:href=\"#m32b42f23f4\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(91.91 239.640156)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"132.2475\" xlink:href=\"#m32b42f23f4\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(125.885 239.640156)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"166.2225\" xlink:href=\"#m32b42f23f4\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(159.86 239.640156)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.1975\" xlink:href=\"#m32b42f23f4\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(193.835 239.640156)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.1725\" xlink:href=\"#m32b42f23f4\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 30 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(227.81 239.640156)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m534ca426fa\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m534ca426fa\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m534ca426fa\" y=\"44.974219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 48.773437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m534ca426fa\" y=\"78.949219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 82.748437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m534ca426fa\" y=\"112.924219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 116.723437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m534ca426fa\" y=\"146.899219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 150.698437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m534ca426fa\" y=\"180.874219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 184.673437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m534ca426fa\" y=\"214.849219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 30 -->\r\n      <g transform=\"translate(7.2 218.648437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 225.041719 \r\nL 26.925 7.601719 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 225.041719 \r\nL 244.365 7.601719 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 225.041719 \r\nL 244.365 225.041719 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.601719 \r\nL 244.365 7.601719 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p8f7d223966\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.601719\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "for img_224, img_32, target in test_loader:\n",
    "    print(img_224.shape, img_32.shape)\n",
    "    print(target)\n",
    "\n",
    "    img = img_32[1].numpy().transpose((1, 2, 0))\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loaded pretrained resnet model\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n)\n"
    }
   ],
   "source": [
    "model = resnet18(pretrained=True, progress=True, layer_4=True, tanh=True).to(0)\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "500it [01:31,  5.44it/s]\n100it [00:19,  5.06it/s]\n"
    },
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.35 GiB for an array with shape (50000, 256, 14, 14) and data type float32",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5c4823a2b418>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtest_featmaps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatmaps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrain_featmaps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_featmaps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mtest_featmaps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_featmaps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.35 GiB for an array with shape (50000, 256, 14, 14) and data type float32"
     ]
    }
   ],
   "source": [
    "train_featmaps = []\n",
    "test_featmaps = []\n",
    "for i, (inputs, inputs_32, targets) in tqdm(enumerate(train_loader)):\n",
    "    inputs, inputs_32, targets = inputs.to(0), inputs_32.to(0), targets.to(0)\n",
    "    featmaps = model(inputs).detach().cpu().numpy()\n",
    "    train_featmaps.extend(featmaps)\n",
    "   \n",
    "for i, (inputs, inputs_32, targets) in tqdm(enumerate(test_loader)):\n",
    "    inputs, inputs_32, targets = inputs.to(0), inputs_32.to(0), targets.to(0)\n",
    "    featmaps = model(inputs).detach().cpu().numpy()\n",
    "    test_featmaps.extend(featmaps)\n",
    "    \n",
    "train_featmaps = np.array(train_featmaps)\n",
    "test_featmaps = np.array(test_featmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.35 GiB for an array with shape (50000, 256, 14, 14) and data type float32",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-67c509b2f4df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_featmaps.npy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_featmaps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_featmaps.npy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_featmaps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0;32m    553\u001b[0m                            pickle_kwargs=pickle_kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.35 GiB for an array with shape (50000, 256, 14, 14) and data type float32"
     ]
    }
   ],
   "source": [
    "np.save(\"train_featmaps.npy\", train_featmaps)\n",
    "np.save(\"test_featmaps.npy\", test_featmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}