{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, color\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import pdb\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
    "           'wide_resnet50_2', 'wide_resnet101_2']\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "}\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, tanh=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.tanh = tanh\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        if self.tanh:\n",
    "            out = nn.Tanh()(out)\n",
    "        else:\n",
    "            out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, tanh=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1], tanh=tanh)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False, tanh=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks-1):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "        layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                            base_width=self.base_width, dilation=self.dilation,\n",
    "                            norm_layer=norm_layer, tanh=tanh))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "#         featmap = x\n",
    "#         x = self.layer4(x)\n",
    "#         x = self.avgpool(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, tanh=False):\n",
    "        super(Discriminator, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 256\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_cls = nn.Linear(512 * block.expansion, 10)\n",
    "        self.fc_adv = nn.Linear(512 * block.expansion, 1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False, tanh=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks-1):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "        layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                            base_width=self.base_width, dilation=self.dilation,\n",
    "                            norm_layer=norm_layer, tanh=tanh))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.layer4(x)\n",
    "        feats = self.avgpool(x)\n",
    "        feats = torch.flatten(feats, 1)\n",
    "        logits_cls = self.fc_cls(feats)\n",
    "        logits_adv = self.fc_adv(feats)\n",
    "        return feats, logits_cls, logits_adv\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, progress, layer_4, fixed, tanh=False):\n",
    "    model = ResNet(block, layers, tanh=tanh)\n",
    "    if pretrained:\n",
    "        model_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "#         model_dict = model_zoo.load_url(\"https://download.pytorch.org/models/resnet18-5c106cde.pth\")\n",
    "#         model_dict.pop('fc.weight', None)\n",
    "#         model_dict.pop('fc.bias', None)\n",
    "        model.load_state_dict(model_dict)\n",
    "        if layer_4:\n",
    "            for name,child in model.named_children():\n",
    "                if name != 'layer4':\n",
    "                    for param in child.parameters():\n",
    "                        param.requires_grad = False\n",
    "        if fixed:\n",
    "            for name,child in model.named_children():\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "    #     model.eval()\n",
    "#         model.load_state_dict(state_dict)\n",
    "    return model\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, width = 12, deconv = False):\n",
    "        super(Generator, self).__init__()\n",
    "        # Input size: [batch, 3, 32, 32]\n",
    "        # Output size: [batch, 3, 32, 32]\n",
    "        nfms = width\n",
    "        if deconv:\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.ConvTranspose2d(512, nfms*8, 4, stride=2, padding=1),  # [batch, width*8, 2, 2]\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.ConvTranspose2d(nfms*8, 256, 4, stride=2, padding=1),  # [batch, width*4, 4, 4]\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.ConvTranspose2d(256, 256, 4, stride=2, padding=1),  # [batch, width*2, 8, 8]\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.ConvTranspose2d(256, 256, 4, stride=2, padding=1),  # [batch, width*1, 16, 16]\n",
    "                nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=0),# [batch, width*1, 14, 14]\n",
    "            )\n",
    "        else:\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Upsample(size=(2,2), mode='nearest'),\n",
    "                nn.Conv2d(512, nfms*8, kernel_size=2, stride=1, padding=1), \n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                # state size. \n",
    "                nn.Upsample(size=(4,4), mode='nearest'),\n",
    "                nn.Conv2d(nfms*8, 256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                # state size. (ngf*8) x 4 x 4\n",
    "                nn.Upsample(size=(8,8), mode='nearest'),\n",
    "                nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                # state size. (ngf*4) x 8 x 8\n",
    "                nn.Upsample(size=(14,14), mode='nearest'),\n",
    "                nn.Conv2d( 256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            )\n",
    "        self.output_act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        decoded = self.decoder(x)\n",
    "        decoded = self.output_act(decoded)\n",
    "        return decoded\n",
    "    \n",
    "def resnet18(pretrained=False, progress=True, layer_4=False, fixed=False, tanh=False):\n",
    "    r\"\"\"ResNet-18 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        print(\"Loaded pretrained resnet model\")\n",
    "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress, layer_4, fixed, tanh=tanh)\n",
    "\n",
    "def discriminator():\n",
    "    return Discriminator(BasicBlock, [2,2,2,2], tanh=False)\n",
    "\n",
    "def generator():\n",
    "    return Generator(width=32, deconv=True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10(Dataset):\n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "    meta = {\n",
    "        'filename': 'batches.meta',\n",
    "        'key': 'label_names',\n",
    "        'md5': '5ff9c542aee3614f3951f8cda6e48888',\n",
    "    }\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "\n",
    "        super(CIFAR10, self).__init__()\n",
    "        self.root = root\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if self.train:\n",
    "            downloaded_list = self.train_list\n",
    "        else:\n",
    "            downloaded_list = self.test_list\n",
    "\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        self.transform = transform\n",
    "        self.target_transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), ])\n",
    "        \n",
    "        # now load the picked numpy arrays\n",
    "        for file_name, checksum in downloaded_list:\n",
    "            file_path = os.path.join(self.root, self.base_folder, file_name)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                entry = pickle.load(f, encoding='latin1')\n",
    "                self.data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.targets.extend(entry['labels'])\n",
    "                else:\n",
    "                    self.targets.extend(entry['fine_labels'])\n",
    "\n",
    "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "        self._load_meta()\n",
    "\n",
    "    def _load_meta(self):\n",
    "        path = os.path.join(self.root, self.base_folder, self.meta['filename'])\n",
    "     \n",
    "        with open(path, 'rb') as infile:\n",
    "            data = pickle.load(infile, encoding='latin1')\n",
    "            self.classes = data[self.meta['key']]\n",
    "        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n",
    "    \n",
    "    def _ret_data(self):\n",
    "        return self.data, self.targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img_, target = self.data[index], self.targets[index]\n",
    "        img_224 = Image.fromarray(img_)\n",
    "        img_32 = Image.fromarray(img_)\n",
    "        img_224 = img_224.resize((224,224), resample=0)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_224 = self.transform(img_224)\n",
    "            img_32 = self.target_transform(img_32)\n",
    "#             target = self.target_transform(target)\n",
    "            \n",
    "        return img_224, img_32, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CIFAR100(CIFAR10):\n",
    "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "\n",
    "    This is a subclass of the `CIFAR10` Dataset.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-100-python'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n",
    "    meta = {\n",
    "        'filename': 'meta',\n",
    "        'key': 'fine_label_names',\n",
    "        'md5': '7973b15100ade9c7d40fb424638fde48',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_featmap(args, model, inputs, targets, criterion):\n",
    "    inputs, targets = inputs.to(args.device), targets.to(args.device)\n",
    "    features, featmaps, gen_image = model(inputs, fixed=args.fixed)\n",
    "    loss = criterion(gen_image, featmaps)\n",
    "    return loss, featmaps, gen_image\n",
    "    \n",
    "def visualize_featmap(featmaps, gen_image, out_dir=None):\n",
    "    for j in range(8):\n",
    "        plt.subplot(2,8,j+1)\n",
    "        plt.imshow((featmaps[0*8+j].detach().cpu().numpy()+1.)/2)\n",
    "        plt.axis('off')\n",
    "    for j in range(8):\n",
    "        plt.subplot(2,8,8+j+1)\n",
    "        plt.imshow((gen_image[0*8+j].detach().cpu().numpy()+1.)/2)\n",
    "        plt.axis('off')\n",
    "#         plt.imshow((gen_image.detach().cpu().numpy().transpose(1,2,0)+1.)/2)\n",
    "    if out_dir is not None:\n",
    "        plt.savefig(out_dir)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, autoencoder, train_loader, optimizer, criterion, train_output_dir=None):\n",
    "    _loss = 0.\n",
    "    for i, (inputs, inputs_32, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss, featmaps, gen_image = train_step(args, autoencoder, inputs, targets, criterion)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _loss += loss.item()\n",
    "        \n",
    "    if epoch % args.visualize_freq == 0 or epoch == 1:\n",
    "        print(\"Epoch {}, Training Iteration {}\".format(epoch, i))\n",
    "        print(\"Loss_mse: \", _loss/(i+1))\n",
    "        visualize(featmaps[0], gen_image[0],\n",
    "                  out_dir = train_output_dir + str(epoch) + \"_\" + str(i) + \".jpg\")\n",
    "    return _loss/(i+1)\n",
    "        \n",
    "def test(args, epoch, autoencoder, test_loader, criterion, test_output_dir=None):\n",
    "    _loss = 0. \n",
    "    for i, (inputs, inputs_32, targets) in enumerate(test_loader):\n",
    "        loss, featmaps, gen_image = train_step(args, autoencoder, inputs, targets, criterion)\n",
    "        _loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            visualize(featmaps[0], gen_image[0],\n",
    "                      out_dir= test_output_dir + str(epoch) +\"_\" + str(i) + \".jpg\")\n",
    "\n",
    "    print(\"Testing epoch \", epoch)\n",
    "    print(\"Test loss MSE: \", _loss/(i+1))\n",
    "    return _loss/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "trainset = CIFAR10(root='./data', train=True,\n",
    "                   download=True, transform=transform)\n",
    "testset = CIFAR10(root='./data', train=False,\n",
    "                  download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 224, 224]) torch.Size([100, 3, 32, 32])\n",
      "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
      "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
      "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
      "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
      "        6, 0, 0, 7])\n"
     ]
    }
   ],
   "source": [
    "for img_224, img_32, target in test_loader:\n",
    "    print(img_224.shape, img_32.shape)\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained resnet model\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=True, progress=True, layer_4=True, tanh=True).to(0)\n",
    "model.eval()\n",
    "train_featmaps = []\n",
    "test_featmaps = []\n",
    "for i, (inputs, inputs_32, targets) in enumerate(train_loader):\n",
    "    inputs, inputs_32, targets = inputs.to(0), inputs_32.to(0), targets.to(0)\n",
    "    featmaps = model(inputs).detach().cpu().numpy()\n",
    "    train_featmaps.extend(featmaps)\n",
    "   \n",
    "for i, (inputs, inputs_32, targets) in enumerate(test_loader):\n",
    "    inputs, inputs_32, targets = inputs.to(0), inputs_32.to(0), targets.to(0)\n",
    "    featmaps = model(inputs).detach().cpu().numpy()\n",
    "    test_featmaps.extend(featmaps)\n",
    "    \n",
    "train_featmaps = np.array(train_featmaps)\n",
    "test_featmaps = np.array(test_featmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_featmaps.npy\", train_featmaps)\n",
    "np.save(\"test_featmaps.npy\", test_featmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
